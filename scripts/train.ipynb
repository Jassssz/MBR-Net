{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "\n",
    "from dataset import load_dataset, polyfit, expfit, shuffle_apply_scaler, perm_distribution\n",
    "from model import MSE_function, huber_fn, MSE_model, huber_model\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.metrics import RootMeanSquaredError, MeanAbsolutePercentageError, MeanAbsoluteError\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, perm_df, param_df, time_df = load_dataset('../dataset/CombinedDataset.xlsx', '1')\n",
    "means, Distribution = perm_distribution(df)\n",
    "X1_arr_train_shuffle, X2_arr_train_shuffle, Y_arr_train_shuffle, X1_arr_valid_shuffle, X2_arr_valid_shuffle, Y_arr_valid_shuffle, X1_arr_test_shuffle, X2_arr_test_shuffle, Y_arr_test_shuffle, timestamp_test = shuffle_apply_scaler(df, perm_df, param_df, time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 1.0\n",
    "ic_pt = means[330]\n",
    "multiplier = 5.0\n",
    "\n",
    "y_max = np.max(Distribution[0]).astype('float32')\n",
    "y_min = np.min(Distribution[0]).astype('float32')\n",
    "\n",
    "p_list = polyfit(df)\n",
    "a_fit, b_fit, c_fit = expfit(df)\n",
    "\n",
    "def custom_loss_function(y_true, y_pred):\n",
    "    delta = 5\n",
    "    diff = y_true - y_pred\n",
    "    is_small_error = tf.abs(diff) < delta\n",
    "    squared_loss = tf.square(diff) / 2\n",
    "    linear_loss  = tf.multiply(tf.abs(diff), delta) - 0.5 * delta**2\n",
    "    error = tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    is_small_value = y_true < ic_pt\n",
    "    polynomial_term = tf.math.polyval(p_list, y_true)\n",
    "    a_fit_float32 = tf.cast(a_fit, dtype=tf.float32)\n",
    "    b_fit_float32 = tf.cast(b_fit, dtype=tf.float32)\n",
    "    c_fit_float32 = tf.cast(c_fit, dtype=tf.float32)\n",
    "    exp_term = tf.add(tf.multiply(a_fit_float32, tf.exp(tf.multiply(-1*b_fit_float32, y_true))), c_fit_float32)\n",
    "    clf_coe = tf.where(is_small_value, polynomial_term, exp_term)\n",
    "    clf_coe_reversed = tf.add(offset,tf.divide(tf.subtract(y_max, clf_coe), tf.subtract(y_max, y_min)))\n",
    "    return K.mean(tf.multiply(tf.multiply(multiplier, clf_coe_reversed), error))\n",
    "\n",
    "def clf_model(index, \n",
    "              X1_arr_train_shuffle, \n",
    "              X2_arr_train_shuffle, \n",
    "              Y_arr_train_shuffle, \n",
    "              X1_arr_valid_shuffle, \n",
    "              X2_arr_valid_shuffle,\n",
    "              Y_arr_valid_shuffle):\n",
    "    num_encoder_features = 3  # Number of input features\n",
    "    num_decoder_features = 6\n",
    "    encoder_seq_len = 900\n",
    "    decoder_seq_len = 180\n",
    "    hidden_dim = 16  # Hidden dimension of LSTM\n",
    "    hidden_dim2 = 8\n",
    "    dropout_rate = 0.1\n",
    "    learning_rate = 0.005\n",
    "\n",
    "    # Build the encoder\n",
    "    encoder_inputs = tf.keras.Input(shape=(encoder_seq_len, num_encoder_features))\n",
    "    encoder_lstm1 = LSTM(hidden_dim, return_state=True, return_sequences=True)\n",
    "    encoder_outputs1, state_h1, state_c1 = encoder_lstm1(encoder_inputs)\n",
    "    encoder_outputs1 = Dropout(dropout_rate)(encoder_outputs1)\n",
    "    encoder_lstm2 = LSTM(hidden_dim2, return_state=True, return_sequences=True)\n",
    "    encoder_outputs2, state_h, state_c = encoder_lstm2(encoder_outputs1)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Build the decoder\n",
    "    decoder_inputs = tf.keras.Input(shape=(decoder_seq_len, num_decoder_features))\n",
    "    decoder_lstm = LSTM(hidden_dim2, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense_1 = Dense(hidden_dim2/2,activation='relu')\n",
    "    decoder_outputs = decoder_dense_1(decoder_outputs)\n",
    "    decoder_dense_2 = Dense(1)\n",
    "    decoder_outputs = decoder_dense_2(decoder_outputs)\n",
    "\n",
    "    # Build the model\n",
    "    model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=custom_loss_function,metrics=[RootMeanSquaredError(),MeanAbsolutePercentageError(),MeanAbsoluteError()])\n",
    "    model.summary()\n",
    "    \n",
    "    batch_size = 1024\n",
    "    epochs = 200\n",
    "    \n",
    "    folder_name = './model/'\n",
    "    file_name = 'R168_Dropout.1_bs1024_lr0.005_Delta5_CLFHuber5_Adam' + str(index)\n",
    "\n",
    "    cp1 = ModelCheckpoint(\n",
    "        filepath=folder_name + file_name + '.h5',\n",
    "        save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "    # early_stopping = EarlyStopping(patience=10, restore_best_weights=True, start_from_epoch=60)\n",
    "    \n",
    "    # Train the model\n",
    "    history=model.fit([X1_arr_train_shuffle, X2_arr_train_shuffle], Y_arr_train_shuffle, validation_data=([X1_arr_valid_shuffle, X2_arr_valid_shuffle], Y_arr_valid_shuffle),\n",
    "                 epochs=epochs, batch_size=batch_size,\n",
    "                 callbacks=[cp1,early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dic = {\n",
    "    'CLF': 'loss',\n",
    "    'RMSE': 'root_mean_squared_error',\n",
    "    'MAPE': 'mean_absolute_percentage_error',\n",
    "    'MSE': 'root_mean_squared_error',\n",
    "    'MAE': 'mean_absolute_error'}\n",
    "\n",
    "def loss_metric_plot(history, save_location, metric_name_str):\n",
    "    history.history.keys()\n",
    "    plt.clf()\n",
    "    plt.plot(history.history[metric_dic[metric_name_str]], label='Training ' + metric_name_str)\n",
    "    plt.plot(history.history['val_' + metric_dic[metric_name_str]], label='Validation ' + metric_name_str)\n",
    "    plt.ylabel(metric_name_str)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(save_location + '_' + metric_name_str + '.png')\n",
    "    plt.show()\n",
    "    return plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = clf_model(0, \n",
    "                    X1_arr_train_shuffle, \n",
    "                    X2_arr_train_shuffle, \n",
    "                    Y_arr_train_shuffle, \n",
    "                    X1_arr_valid_shuffle, \n",
    "                    X2_arr_valid_shuffle,\n",
    "                    Y_arr_valid_shuffle)\n",
    "folder_name = './model/'\n",
    "file_name = 'R168_Dropout.1_bs1024_lr0.005_Delta5_CLFHuber5_Adam' + str(0)\n",
    "loss_metric_plot(history, folder_name + 'graph/' + file_name, 'CLF')\n",
    "loss_metric_plot(history, folder_name + 'graph/' + file_name, 'MAPE')\n",
    "loss_metric_plot(history, folder_name + 'graph/' + file_name, 'RMSE')\n",
    "loss_metric_plot(history, folder_name + 'graph/' + file_name, 'MAE')\n",
    "\n",
    "# #train multiple models\n",
    "# for i in range(10):\n",
    "#     history = clf_model(i)\n",
    "#     folder_name = './model/'\n",
    "#     file_name = 'R168_Dropout.1_bs1024_lr0.005_Delta5_CLFHuber5_Adam' + str(i)\n",
    "#     loss_metric_plot(history, folder_name + 'graph/' + file_name, 'CLF')\n",
    "#     loss_metric_plot(history, folder_name + 'graph/' + file_name, 'MAPE')\n",
    "#     loss_metric_plot(history, folder_name + 'graph/' + file_name, 'RMSE')\n",
    "#     loss_metric_plot(history, folder_name + 'graph/' + file_name, 'MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = MSE_model(0, \n",
    "                    X1_arr_train_shuffle, \n",
    "                    X2_arr_train_shuffle, \n",
    "                    Y_arr_train_shuffle, \n",
    "                    X1_arr_valid_shuffle, \n",
    "                    X2_arr_valid_shuffle,\n",
    "                    Y_arr_valid_shuffle)\n",
    "folder_name = './model/'\n",
    "file_name = 'R168_Dropout.1_bs1024_lr0.005_MSE' + str(0)\n",
    "loss_metric_plot(history, folder_name + 'graph/' + file_name, 'CLF')\n",
    "loss_metric_plot(history, folder_name + 'graph/' + file_name, 'MAPE')\n",
    "loss_metric_plot(history, folder_name + 'graph/' + file_name, 'RMSE')\n",
    "loss_metric_plot(history, folder_name + 'graph/' + file_name, 'MAE')\n",
    "\n",
    "# #train multiple models\n",
    "# for i in range(10):\n",
    "#     history = MSE_model(i, \n",
    "#                     X1_arr_train_shuffle, \n",
    "#                     X2_arr_train_shuffle, \n",
    "#                     Y_arr_train_shuffle, \n",
    "#                     X1_arr_valid_shuffle, \n",
    "#                     X2_arr_valid_shuffle,\n",
    "#                     Y_arr_valid_shuffle)\n",
    "#     folder_name = './model/'\n",
    "#     file_name = 'R168_Dropout.1_bs1024_lr0.005_MSE' + str(i)\n",
    "#     loss_metric_plot(history, folder_name + 'graph/' + file_name, 'CLF')\n",
    "#     loss_metric_plot(history, folder_name + 'graph/' + file_name, 'MAPE')\n",
    "#     loss_metric_plot(history, folder_name + 'graph/' + file_name, 'RMSE')\n",
    "#     loss_metric_plot(history, folder_name + 'graph/' + file_name, 'MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = huber_model(0, \n",
    "                    X1_arr_train_shuffle, \n",
    "                    X2_arr_train_shuffle, \n",
    "                    Y_arr_train_shuffle, \n",
    "                    X1_arr_valid_shuffle, \n",
    "                    X2_arr_valid_shuffle,\n",
    "                    Y_arr_valid_shuffle)\n",
    "folder_name = './model/'\n",
    "file_name = 'R1616_Dropout.1_bs1024_lr0.005_Huber5_softmax' + str(0)\n",
    "loss_metric_plot(history, folder_name + 'graph/' + file_name, 'CLF')\n",
    "loss_metric_plot(history, folder_name + 'graph/' + file_name, 'MAPE')\n",
    "loss_metric_plot(history, folder_name + 'graph/' + file_name, 'RMSE')\n",
    "loss_metric_plot(history, folder_name + 'graph/' + file_name, 'MAE')\n",
    "\n",
    "# #train multiple models\n",
    "# for i in range(5):\n",
    "#     history = huber_model(i, \n",
    "#                     X1_arr_train_shuffle, \n",
    "#                     X2_arr_train_shuffle, \n",
    "#                     Y_arr_train_shuffle, \n",
    "#                     X1_arr_valid_shuffle, \n",
    "#                     X2_arr_valid_shuffle,\n",
    "#                     Y_arr_valid_shuffle)\n",
    "#     folder_name = './model/'\n",
    "#     file_name = 'R1616_Dropout.1_bs1024_lr0.005_Huber5_softmax' + str(i)\n",
    "#     loss_metric_plot(history, folder_name + 'graph/' + file_name, 'CLF')\n",
    "#     loss_metric_plot(history, folder_name + 'graph/' + file_name, 'MAPE')\n",
    "#     loss_metric_plot(history, folder_name + 'graph/' + file_name, 'RMSE')\n",
    "#     loss_metric_plot(history, folder_name + 'graph/' + file_name, 'MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
