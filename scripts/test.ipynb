{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import r2_score\n",
    "from dataset import load_dataset, polyfit, expfit, shuffle_apply_scaler, perm_distribution, shuffle_apply_scaler_testing\n",
    "from model import MSE_function, huber_fn, MSE_model, huber_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.metrics import RootMeanSquaredError, MeanAbsolutePercentageError, MeanAbsoluteError\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, perm_df, param_df, time_df = load_dataset('../dataset/CombinedDataset.xlsx', '1')\n",
    "means, Distribution = perm_distribution(df)\n",
    "X1_arr_train_shuffle, X2_arr_train_shuffle, Y_arr_train_shuffle, X1_arr_valid_shuffle, X2_arr_valid_shuffle, Y_arr_valid_shuffle, X1_arr_test_shuffle, X2_arr_test_shuffle, Y_arr_test_shuffle, timestamp_test = shuffle_apply_scaler(df, perm_df, param_df, time_df)\n",
    "\n",
    "df_testing, perm_df_testing, param_df_testing, time_df_testing = load_dataset('../dataset/CombinedDataset_testing.xlsx','1')\n",
    "X1_arr_shuffle_testing, X2_arr_shuffle_testing, Y_arr_shuffle_testing = shuffle_apply_scaler_testing(df,df_testing,perm_df_testing,param_df_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 1.0\n",
    "ic_pt = means[330]\n",
    "multiplier = 5.0\n",
    "\n",
    "y_max = np.max(Distribution[0]).astype('float32')\n",
    "y_min = np.min(Distribution[0]).astype('float32')\n",
    "\n",
    "p_list = polyfit(df)\n",
    "a_fit, b_fit, c_fit = expfit(df)\n",
    "\n",
    "def custom_loss_function(y_true, y_pred):\n",
    "    delta = 5\n",
    "    diff = y_true - y_pred\n",
    "    is_small_error = tf.abs(diff) < delta\n",
    "    squared_loss = tf.square(diff) / 2\n",
    "    linear_loss  = tf.multiply(tf.abs(diff), delta) - 0.5 * delta**2\n",
    "    error = tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    is_small_value = y_true < ic_pt\n",
    "    polynomial_term = tf.math.polyval(p_list, y_true)\n",
    "    a_fit_float32 = tf.cast(a_fit, dtype=tf.float32)\n",
    "    b_fit_float32 = tf.cast(b_fit, dtype=tf.float32)\n",
    "    c_fit_float32 = tf.cast(c_fit, dtype=tf.float32)\n",
    "    exp_term = tf.add(tf.multiply(a_fit_float32, tf.exp(tf.multiply(-1*b_fit_float32, y_true))), c_fit_float32)\n",
    "    clf_coe = tf.where(is_small_value, polynomial_term, exp_term)\n",
    "    clf_coe_reversed = tf.add(offset,tf.divide(tf.subtract(y_max, clf_coe), tf.subtract(y_max, y_min)))\n",
    "    return K.mean(tf.multiply(tf.multiply(multiplier, clf_coe_reversed), error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../models/R168_Dropout.1_bs1024_lr0.005_Delta5_CLFHuber5_Adam'\n",
    "filepath=os.path.join(file_name + '.h5')\n",
    "regressor=load_model(filepath,\n",
    "                     custom_objects={'custom_loss_function': custom_loss_function})\n",
    "\n",
    "# file_name = '../models/model_repetitions/R1616_Dropout.1_bs1024_lr0.005_Huber5_softmax0'\n",
    "# filepath=os.path.join(file_name + '.h5')\n",
    "# regressor=load_model(filepath,\n",
    "#                      custom_objects={'huber_fn': huber_fn})\n",
    "\n",
    "# file_name = '../models/model_repetitions/R168_Dropout.1_bs1024_lr0.005_MSE0'\n",
    "# filepath=os.path.join(file_name + '.h5')\n",
    "# regressor=load_model(filepath,\n",
    "#                      custom_objects={'MSE_function': MSE_function})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perm_Max=max(df['Permeability'])\n",
    "Perm_Min=min(df['Permeability'])\n",
    "Perm_Max, Perm_Min\n",
    "\n",
    "def postprocess_perm(arr):\n",
    "    arr=arr*(Perm_Max-Perm_Min)+Perm_Min\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance on testing set 1\n",
    "predictions = regressor.predict([X1_arr_test_shuffle, X2_arr_test_shuffle])\n",
    "\n",
    "predictions_flat = postprocess_perm(predictions.flatten())\n",
    "Y_arr_test_shuffle_flat = postprocess_perm(Y_arr_test_shuffle.flatten())\n",
    "\n",
    "mape = abs((predictions_flat-Y_arr_test_shuffle_flat)/Y_arr_test_shuffle_flat)\n",
    "r2 = r2_score(Y_arr_test_shuffle_flat, predictions_flat)\n",
    "mse = ((predictions_flat - Y_arr_test_shuffle_flat)**2)\n",
    "mae = abs(predictions_flat - Y_arr_test_shuffle_flat)\n",
    "\n",
    "print(\"MAPE: \"+str(mape.mean()))\n",
    "print(\"r2: \"+str(r2))\n",
    "print(\"MAE: \"+str(mae.mean()))\n",
    "print(\"MSE: \"+str(mse.mean()))\n",
    "print(\"RMSE: \"+str(math.sqrt(mse.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance on testing set 2\n",
    "predictions = regressor.predict([X1_arr_shuffle_testing, X2_arr_shuffle_testing])\n",
    "\n",
    "predictions_flat = postprocess_perm(predictions.flatten())\n",
    "Y_arr_test_shuffle_flat = postprocess_perm(Y_arr_shuffle_testing.flatten())\n",
    "\n",
    "mape = abs((predictions_flat-Y_arr_test_shuffle_flat)/Y_arr_test_shuffle_flat)\n",
    "r2 = r2_score(Y_arr_test_shuffle_flat, predictions_flat)\n",
    "mse=((predictions_flat-Y_arr_test_shuffle_flat)**2)\n",
    "mae=abs(predictions_flat-Y_arr_test_shuffle_flat)\n",
    "\n",
    "print(\"MAPE: \"+str(mape.mean()))\n",
    "print(\"r2: \"+str(r2))\n",
    "print(\"MAE: \"+ str(mae.mean()))\n",
    "print(\"MSE: \"+str(mse.mean()))\n",
    "print(\"RMSE: \"+str(math.sqrt(mse.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['MAPE_set1', 'R2_set1', 'MAE_set1', 'MSE_set1', 'RMSE_set1', 'MAPE_set2', 'R2_set2', 'MAE_set2', 'MSE_set2', 'RMSE_set2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_model(index):\n",
    "    folder_name = '../models/model_repetitions/'\n",
    "\n",
    "    file_name = 'R168_Dropout.1_bs1024_lr0.005_Delta5_CLFHuber5_Adam' + str(index)\n",
    "    # file_name = 'R1616_Dropout.1_bs1024_lr0.005_Huber5_softmax' + str(index)\n",
    "    # file_name = 'R168_Dropout.1_bs1024_lr0.005_MSE' + str(index)\n",
    "    \n",
    "    filepath=os.path.join(folder_name + file_name + '.h5')\n",
    "    regressor=load_model(filepath,\n",
    "                         custom_objects={'custom_loss_function': custom_loss_function})\n",
    "    # regressor=load_model(filepath,\n",
    "    #                      custom_objects={'huber_fn': huber_fn})\n",
    "    # regressor=load_model(filepath,\n",
    "    #                      custom_objects={'MSE_function': MSE_function})\n",
    "    \n",
    "\n",
    "    print('This is set #' + str(index))\n",
    "    set1_metrics = set1_pred(regressor)\n",
    "    set2_metrics = set2_pred(regressor)\n",
    "\n",
    "    # Append the results to the DataFrame\n",
    "    global results_df\n",
    "    new_row = pd.DataFrame([{\n",
    "        **set1_metrics,\n",
    "        **set2_metrics\n",
    "    }])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "def set1_pred(regressor):\n",
    "    predictions = regressor.predict([X1_arr_test_shuffle, X2_arr_test_shuffle])\n",
    "    \n",
    "    predictions_flat = postprocess_perm(predictions.flatten())\n",
    "    Y_arr_test_shuffle_flat = postprocess_perm(Y_arr_test_shuffle.flatten())\n",
    "    \n",
    "    #mape\n",
    "    mape = abs((predictions_flat-Y_arr_test_shuffle_flat)/Y_arr_test_shuffle_flat)\n",
    "    r2 = r2_score(Y_arr_test_shuffle_flat, predictions_flat)\n",
    "    mse = ((predictions_flat - Y_arr_test_shuffle_flat)**2)\n",
    "    mae = abs(predictions_flat - Y_arr_test_shuffle_flat)\n",
    "    \n",
    "    print(\"MAPE: \"+str(mape.mean()))\n",
    "    print(\"r2: \"+str(r2))\n",
    "    print(\"MAE: \"+str(mae.mean()))\n",
    "    print(\"MSE: \"+str(mse.mean()))\n",
    "    print(\"RMSE: \"+str(math.sqrt(mse.mean())))\n",
    "    return {\n",
    "        'MAPE_set1': mape.mean(),\n",
    "        'R2_set1': r2,\n",
    "        'MAE_set1': mae.mean(),\n",
    "        'MSE_set1': mse.mean(),\n",
    "        'RMSE_set1': math.sqrt(mse.mean())\n",
    "    }\n",
    "\n",
    "\n",
    "def set2_pred(regressor):\n",
    "    predictions = regressor.predict([X1_arr_shuffle_testing, X2_arr_shuffle_testing])\n",
    "    \n",
    "    predictions_flat = postprocess_perm(predictions.flatten())\n",
    "    Y_arr_test_shuffle_flat = postprocess_perm(Y_arr_shuffle_testing.flatten())\n",
    "    \n",
    "    #mape\n",
    "    mape = abs((predictions_flat-Y_arr_test_shuffle_flat)/Y_arr_test_shuffle_flat)\n",
    "    from sklearn.metrics import r2_score\n",
    "    import math\n",
    "    r2 = r2_score(Y_arr_test_shuffle_flat, predictions_flat)\n",
    "    mse=((predictions_flat-Y_arr_test_shuffle_flat)**2)\n",
    "    mae=abs(predictions_flat-Y_arr_test_shuffle_flat)\n",
    "    \n",
    "    print(\"MAPE: \"+str(mape.mean()))\n",
    "    print(\"r2: \"+str(r2))\n",
    "    print(\"MAE: \"+ str(mae.mean()))\n",
    "    print(\"MSE: \"+str(mse.mean()))\n",
    "    print(\"RMSE: \"+str(math.sqrt(mse.mean())))\n",
    "    print(\"\\n\")\n",
    "    return {\n",
    "        'MAPE_set2': mape.mean(),\n",
    "        'R2_set2': r2,\n",
    "        'MAE_set2': mae.mean(),\n",
    "        'MSE_set2': mse.mean(),\n",
    "        'RMSE_set2': math.sqrt(mse.mean())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['MAPE_set1', 'R2_set1', 'MAE_set1', 'MSE_set1', 'RMSE_set1', 'MAPE_set2', 'R2_set2', 'MAE_set2', 'MSE_set2', 'RMSE_set2'])\n",
    "for index in range(40):\n",
    "    pred_model(index)\n",
    "results_df    \n",
    "# results_df.to_excel('results.xlsx', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
