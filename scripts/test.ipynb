{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import r2_score\n",
    "from dataset import load_dataset, polyfit, expfit, shuffle_apply_scaler, perm_distribution, shuffle_apply_scaler_testing\n",
    "from model import MSE_function, huber_fn, MSE_model, huber_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.metrics import RootMeanSquaredError, MeanAbsolutePercentageError, MeanAbsoluteError\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\admin\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\admin\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df, perm_df, param_df, time_df = load_dataset('../dataset/CombinedDataset.xlsx', '1')\n",
    "means, Distribution = perm_distribution(df)\n",
    "X1_arr_train_shuffle, X2_arr_train_shuffle, Y_arr_train_shuffle, X1_arr_valid_shuffle, X2_arr_valid_shuffle, Y_arr_valid_shuffle, X1_arr_test_shuffle, X2_arr_test_shuffle, Y_arr_test_shuffle, timestamp_test = shuffle_apply_scaler(df, perm_df, param_df, time_df)\n",
    "\n",
    "df_testing, perm_df_testing, param_df_testing, time_df_testing = load_dataset('../dataset/CombinedDataset_testing.xlsx','1')\n",
    "X1_arr_shuffle_testing, X2_arr_shuffle_testing, Y_arr_shuffle_testing = shuffle_apply_scaler_testing(df,df_testing,perm_df_testing,param_df_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 1.0\n",
    "ic_pt = means[330]\n",
    "multiplier = 5.0\n",
    "\n",
    "y_max = np.max(Distribution[0]).astype('float32')\n",
    "y_min = np.min(Distribution[0]).astype('float32')\n",
    "\n",
    "p_list = polyfit(df)\n",
    "a_fit, b_fit, c_fit = expfit(df)\n",
    "\n",
    "def custom_loss_function(y_true, y_pred):\n",
    "    delta = 5\n",
    "    diff = y_true - y_pred\n",
    "    is_small_error = tf.abs(diff) < delta\n",
    "    squared_loss = tf.square(diff) / 2\n",
    "    linear_loss  = tf.multiply(tf.abs(diff), delta) - 0.5 * delta**2\n",
    "    error = tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    is_small_value = y_true < ic_pt\n",
    "    polynomial_term = tf.math.polyval(p_list, y_true)\n",
    "    a_fit_float32 = tf.cast(a_fit, dtype=tf.float32)\n",
    "    b_fit_float32 = tf.cast(b_fit, dtype=tf.float32)\n",
    "    c_fit_float32 = tf.cast(c_fit, dtype=tf.float32)\n",
    "    exp_term = tf.add(tf.multiply(a_fit_float32, tf.exp(tf.multiply(-1*b_fit_float32, y_true))), c_fit_float32)\n",
    "    clf_coe = tf.where(is_small_value, polynomial_term, exp_term)\n",
    "    clf_coe_reversed = tf.add(offset,tf.divide(tf.subtract(y_max, clf_coe), tf.subtract(y_max, y_min)))\n",
    "    return K.mean(tf.multiply(tf.multiply(multiplier, clf_coe_reversed), error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../models/R168_Dropout.1_bs1024_lr0.005_Delta5_CLFHuber5_Adam'\n",
    "filepath=os.path.join(file_name + '.h5')\n",
    "regressor=load_model(filepath,\n",
    "                     custom_objects={'custom_loss_function': custom_loss_function})\n",
    "\n",
    "# file_name = '../models/model_repetitions/R1616_Dropout.1_bs1024_lr0.005_Huber5_softmax0'\n",
    "# filepath=os.path.join(file_name + '.h5')\n",
    "# regressor=load_model(filepath,\n",
    "#                      custom_objects={'huber_fn': huber_fn})\n",
    "\n",
    "# file_name = '../models/model_repetitions/R168_Dropout.1_bs1024_lr0.005_MSE0'\n",
    "# filepath=os.path.join(file_name + '.h5')\n",
    "# regressor=load_model(filepath,\n",
    "#                      custom_objects={'MSE_function': MSE_function})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perm_Max=max(df['Permeability'])\n",
    "Perm_Min=min(df['Permeability'])\n",
    "Perm_Max, Perm_Min\n",
    "\n",
    "def postprocess_perm(arr):\n",
    "    arr=arr*(Perm_Max-Perm_Min)+Perm_Min\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114/1114 [==============================] - 33s 29ms/step\n",
      "MAPE: 0.06750317112143457\n",
      "r2: 0.8658438238419849\n",
      "MAE: 3.9176192055417003\n",
      "MSE: 33.675088792149005\n",
      "RMSE: 5.803024107493351\n"
     ]
    }
   ],
   "source": [
    "#performance on testing set 1\n",
    "predictions = regressor.predict([X1_arr_test_shuffle, X2_arr_test_shuffle])\n",
    "\n",
    "predictions_flat = postprocess_perm(predictions.flatten())\n",
    "Y_arr_test_shuffle_flat = postprocess_perm(Y_arr_test_shuffle.flatten())\n",
    "\n",
    "mape = abs((predictions_flat-Y_arr_test_shuffle_flat)/Y_arr_test_shuffle_flat)\n",
    "r2 = r2_score(Y_arr_test_shuffle_flat, predictions_flat)\n",
    "mse = ((predictions_flat - Y_arr_test_shuffle_flat)**2)\n",
    "mae = abs(predictions_flat - Y_arr_test_shuffle_flat)\n",
    "\n",
    "print(\"MAPE: \"+str(mape.mean()))\n",
    "print(\"r2: \"+str(r2))\n",
    "print(\"MAE: \"+str(mae.mean()))\n",
    "print(\"MSE: \"+str(mse.mean()))\n",
    "print(\"RMSE: \"+str(math.sqrt(mse.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643/643 [==============================] - 18s 29ms/step\n",
      "MAPE: 0.06384467457902218\n",
      "r2: 0.8490514170216203\n",
      "MAE: 3.2596176645229367\n",
      "MSE: 26.20543907658134\n",
      "RMSE: 5.119124835026134\n"
     ]
    }
   ],
   "source": [
    "# performance on testing set 2\n",
    "predictions = regressor.predict([X1_arr_shuffle_testing, X2_arr_shuffle_testing])\n",
    "\n",
    "predictions_flat = postprocess_perm(predictions.flatten())\n",
    "Y_arr_test_shuffle_flat = postprocess_perm(Y_arr_shuffle_testing.flatten())\n",
    "\n",
    "mape = abs((predictions_flat-Y_arr_test_shuffle_flat)/Y_arr_test_shuffle_flat)\n",
    "r2 = r2_score(Y_arr_test_shuffle_flat, predictions_flat)\n",
    "mse=((predictions_flat-Y_arr_test_shuffle_flat)**2)\n",
    "mae=abs(predictions_flat-Y_arr_test_shuffle_flat)\n",
    "\n",
    "print(\"MAPE: \"+str(mape.mean()))\n",
    "print(\"r2: \"+str(r2))\n",
    "print(\"MAE: \"+ str(mae.mean()))\n",
    "print(\"MSE: \"+str(mse.mean()))\n",
    "print(\"RMSE: \"+str(math.sqrt(mse.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['MAPE_set1', 'R2_set1', 'MAE_set1', 'MSE_set1', 'RMSE_set1', 'MAPE_set2', 'R2_set2', 'MAE_set2', 'MSE_set2', 'RMSE_set2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_model(index):\n",
    "    folder_name = '../models/model_repetitions/'\n",
    "\n",
    "    file_name = 'R168_Dropout.1_bs1024_lr0.005_Delta5_CLFHuber5_Adam' + str(index)\n",
    "    # file_name = 'R1616_Dropout.1_bs1024_lr0.005_Huber5_softmax' + str(index)\n",
    "    # file_name = 'R168_Dropout.1_bs1024_lr0.005_MSE' + str(index)\n",
    "    \n",
    "    filepath=os.path.join(folder_name + file_name + '.h5')\n",
    "    regressor=load_model(filepath,\n",
    "                         custom_objects={'custom_loss_function': custom_loss_function})\n",
    "    # regressor=load_model(filepath,\n",
    "    #                      custom_objects={'huber_fn': huber_fn})\n",
    "    # regressor=load_model(filepath,\n",
    "    #                      custom_objects={'MSE_function': MSE_function})\n",
    "    \n",
    "\n",
    "    print('This is set #' + str(index))\n",
    "    set1_metrics = set1_pred(regressor)\n",
    "    set2_metrics = set2_pred(regressor)\n",
    "\n",
    "    # Append the results to the DataFrame\n",
    "    global results_df\n",
    "    new_row = pd.DataFrame([{\n",
    "        **set1_metrics,\n",
    "        **set2_metrics\n",
    "    }])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "def set1_pred(regressor):\n",
    "    predictions = regressor.predict([X1_arr_test_shuffle, X2_arr_test_shuffle])\n",
    "    \n",
    "    predictions_flat = postprocess_perm(predictions.flatten())\n",
    "    Y_arr_test_shuffle_flat = postprocess_perm(Y_arr_test_shuffle.flatten())\n",
    "    \n",
    "    #mape\n",
    "    mape = abs((predictions_flat-Y_arr_test_shuffle_flat)/Y_arr_test_shuffle_flat)\n",
    "    r2 = r2_score(Y_arr_test_shuffle_flat, predictions_flat)\n",
    "    mse = ((predictions_flat - Y_arr_test_shuffle_flat)**2)\n",
    "    mae = abs(predictions_flat - Y_arr_test_shuffle_flat)\n",
    "    \n",
    "    print(\"MAPE: \"+str(mape.mean()))\n",
    "    print(\"r2: \"+str(r2))\n",
    "    print(\"MAE: \"+str(mae.mean()))\n",
    "    print(\"MSE: \"+str(mse.mean()))\n",
    "    print(\"RMSE: \"+str(math.sqrt(mse.mean())))\n",
    "    return {\n",
    "        'MAPE_set1': mape.mean(),\n",
    "        'R2_set1': r2,\n",
    "        'MAE_set1': mae.mean(),\n",
    "        'MSE_set1': mse.mean(),\n",
    "        'RMSE_set1': math.sqrt(mse.mean())\n",
    "    }\n",
    "\n",
    "\n",
    "def set2_pred(regressor):\n",
    "    predictions = regressor.predict([X1_arr_shuffle_testing, X2_arr_shuffle_testing])\n",
    "    \n",
    "    predictions_flat = postprocess_perm(predictions.flatten())\n",
    "    Y_arr_test_shuffle_flat = postprocess_perm(Y_arr_shuffle_testing.flatten())\n",
    "    \n",
    "    #mape\n",
    "    mape = abs((predictions_flat-Y_arr_test_shuffle_flat)/Y_arr_test_shuffle_flat)\n",
    "    from sklearn.metrics import r2_score\n",
    "    import math\n",
    "    r2 = r2_score(Y_arr_test_shuffle_flat, predictions_flat)\n",
    "    mse=((predictions_flat-Y_arr_test_shuffle_flat)**2)\n",
    "    mae=abs(predictions_flat-Y_arr_test_shuffle_flat)\n",
    "    \n",
    "    print(\"MAPE: \"+str(mape.mean()))\n",
    "    print(\"r2: \"+str(r2))\n",
    "    print(\"MAE: \"+ str(mae.mean()))\n",
    "    print(\"MSE: \"+str(mse.mean()))\n",
    "    print(\"RMSE: \"+str(math.sqrt(mse.mean())))\n",
    "    print(\"\\n\")\n",
    "    return {\n",
    "        'MAPE_set2': mape.mean(),\n",
    "        'R2_set2': r2,\n",
    "        'MAE_set2': mae.mean(),\n",
    "        'MSE_set2': mse.mean(),\n",
    "        'RMSE_set2': math.sqrt(mse.mean())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is set #0\n",
      "1114/1114 [==============================] - 32s 29ms/step\n",
      "MAPE: 0.06779824340170519\n",
      "r2: 0.8614164485485235\n",
      "MAE: 3.8789280355611657\n",
      "MSE: 34.78642231694975\n",
      "RMSE: 5.898001552810049\n",
      "643/643 [==============================] - 18s 28ms/step\n",
      "MAPE: 0.0655269721674943\n",
      "r2: 0.8613541594606988\n",
      "MAE: 3.3028927250979496\n",
      "MSE: 24.069620633632987\n",
      "RMSE: 4.906079966086263\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_19076\\2922273650.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is set #1\n",
      "1114/1114 [==============================] - 32s 29ms/step\n",
      "MAPE: 0.06639732528329675\n",
      "r2: 0.8566509646905189\n",
      "MAE: 3.953980609284338\n",
      "MSE: 35.98262585115635\n",
      "RMSE: 5.998551979532756\n",
      "643/643 [==============================] - 18s 28ms/step\n",
      "MAPE: 0.06534999534908557\n",
      "r2: 0.8649696596405594\n",
      "MAE: 3.370397162768772\n",
      "MSE: 23.441951477518586\n",
      "RMSE: 4.841688907552672\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns=['MAPE_set1', 'R2_set1', 'MAE_set1', 'MSE_set1', 'RMSE_set1', 'MAPE_set2', 'R2_set2', 'MAE_set2', 'MSE_set2', 'RMSE_set2'])\n",
    "for index in range(40):\n",
    "    pred_model(index)\n",
    "results_df    \n",
    "# results_df.to_excel('results.xlsx', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAPE_set1</th>\n",
       "      <th>R2_set1</th>\n",
       "      <th>MAE_set1</th>\n",
       "      <th>MSE_set1</th>\n",
       "      <th>RMSE_set1</th>\n",
       "      <th>MAPE_set2</th>\n",
       "      <th>R2_set2</th>\n",
       "      <th>MAE_set2</th>\n",
       "      <th>MSE_set2</th>\n",
       "      <th>RMSE_set2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067798</td>\n",
       "      <td>0.861416</td>\n",
       "      <td>3.878928</td>\n",
       "      <td>34.786422</td>\n",
       "      <td>5.898002</td>\n",
       "      <td>0.065527</td>\n",
       "      <td>0.861354</td>\n",
       "      <td>3.302893</td>\n",
       "      <td>24.069621</td>\n",
       "      <td>4.906080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066397</td>\n",
       "      <td>0.856651</td>\n",
       "      <td>3.953981</td>\n",
       "      <td>35.982626</td>\n",
       "      <td>5.998552</td>\n",
       "      <td>0.065350</td>\n",
       "      <td>0.864970</td>\n",
       "      <td>3.370397</td>\n",
       "      <td>23.441951</td>\n",
       "      <td>4.841689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MAPE_set1   R2_set1  MAE_set1   MSE_set1  RMSE_set1  MAPE_set2   R2_set2  \\\n",
       "0   0.067798  0.861416  3.878928  34.786422   5.898002   0.065527  0.861354   \n",
       "1   0.066397  0.856651  3.953981  35.982626   5.998552   0.065350  0.864970   \n",
       "\n",
       "   MAE_set2   MSE_set2  RMSE_set2  \n",
       "0  3.302893  24.069621   4.906080  \n",
       "1  3.370397  23.441951   4.841689  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
